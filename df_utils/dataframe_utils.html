<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>dataworks.df_utils.dataframe_utils API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dataworks.df_utils.dataframe_utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd

from collections import OrderedDict
from pandas.api.types import is_numeric_dtype, is_object_dtype, is_categorical_dtype
from typing import List, Optional, Tuple, Callable


def inspect_df(df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Show column types and null values in DataFrame df
    &#34;&#34;&#34;

    resdict = OrderedDict()

    # Inspect nulls
    null_series = df.isnull().sum()
    resdict[&#34;column&#34;] = null_series.index
    resdict[&#34;null_fraction&#34;] = np.round(null_series.values / len(df), 3)
    resdict[&#34;nulls&#34;] = null_series.values
    # Inspect types
    types = df.dtypes.values
    type_names = [t.name for t in types]
    resdict[&#34;type&#34;] = type_names
    # Is numeric?
    is_numeric = []
    for col in df.columns:
        is_numeric.append(is_numeric_dtype(df[col]))
    resdict[&#34;is_numeric&#34;] = is_numeric
    # Dataframe
    resdf = pd.DataFrame(resdict)
    resdf.sort_values(&#34;null_fraction&#34;, inplace=True)
    resdf.reset_index(inplace=True, drop=True)

    return resdf


def summarize_df(df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Show stats;
        - rows:
            - column types
        - columns
            - number of columns
            - number of cols containing NaN&#39;s
    &#34;&#34;&#34;
    # Original DataFrame
    (nrows, _) = df.shape
    # Stats of DataFrame
    stats = inspect_df(df)
    data_types = np.unique(stats[&#34;type&#34;].values)

    resdict = OrderedDict()

    # Column: data types
    resdict[&#34;type&#34;] = data_types

    ncols_type = []
    ncols_nan = []
    n_nans = []
    n_total = []

    for dt in data_types:
        # Column: number of columns with type
        nc = len(stats[stats[&#34;type&#34;] == dt])
        ncols_type.append(nc)

        # Column: number of columns with NaNs
        nan_cols = stats[(stats[&#34;type&#34;] == dt) &amp; (stats[&#34;nulls&#34;] &gt; 0)]
        ncols_nan.append(len(nan_cols))

        # Column: number of NaNs
        n_nans.append(nan_cols[&#34;nulls&#34;].sum())

        # Column: total number of values
        n_total.append(nc * nrows)

    # Prepare dict for the df
    resdict[&#34;ncols&#34;] = ncols_type
    resdict[&#34;ncols_w_nans&#34;] = ncols_nan
    resdict[&#34;n_nans&#34;] = n_nans
    resdict[&#34;n_total&#34;] = n_total

    # Proportions of NaNs in each column group.
    # Division by zero shouldn&#39;t occur
    nan_frac = np.array(n_nans) / np.array(n_total)
    resdict[&#34;nan_frac&#34;] = np.round(nan_frac, 2)

    resdf = pd.DataFrame(resdict)
    resdf.sort_values(&#34;type&#34;, inplace=True)
    resdf.reset_index(inplace=True, drop=True)

    return resdf


def add_datefields(
    df: pd.DataFrame,
    column: str,
    drop_original: bool = False,
    inplace: bool = False,
    attrs: Optional[List[str]] = None,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Add attributes of the date to dataFrame df
    &#34;&#34;&#34;
    raw_date = df[column]

    # Pandas datetime attributes
    if attrs is None:
        attributes = [
            &#34;dayofweek&#34;,
            &#34;dayofyear&#34;,
            &#34;is_month_end&#34;,
            &#34;is_month_start&#34;,
            &#34;is_quarter_end&#34;,
            &#34;is_quarter_start&#34;,
            &#34;quarter&#34;,
            &#34;week&#34;,
        ]
    else:
        attributes = attrs

    # Return new?
    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    # Could probably be optimized with pd.apply()
    for attr in attributes:
        new_column = f&#34;{column}_{attr}&#34;
        # https://stackoverflow.com/questions/2612610/
        new_vals = [getattr(d, attr) for d in raw_date]
        resdf[new_column] = new_vals

    if drop_original:
        resdf.drop(columns=column, inplace=True)

    return resdf


def add_nan_columns(
    df: pd.DataFrame, inplace: bool = False, column_list: Optional[List[str]] = None
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; For each column containing NaNs, add a boolean
        column specifying if the column is NaN. Can be used
        if the data is later imputated.
    &#34;&#34;&#34;
    if column_list is not None:
        nan_columns = column_list
    else:
        # Get names of columns containing at least one NaN
        temp = df.isnull().sum() != 0
        nan_columns = temp.index[temp.values]

    # Return new?
    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    for column in nan_columns:
        new_column = f&#34;{column}_isnull&#34;
        nans = df[column].isnull()
        resdf[new_column] = nans

    return resdf


def numeric_nans(df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Inspect numerical NaN values of a DataFrame df
    &#34;&#34;&#34;
    stats = inspect_df(df)
    nan_stats = stats.loc[stats[&#34;is_numeric&#34;] &amp; (stats[&#34;nulls&#34;] &gt; 0)].copy(deep=True)

    len_uniques = []
    uniques = []

    for row in nan_stats[&#34;column&#34;].values:
        uniq = np.unique(df[row][df[row].notnull()].values)
        len_uniques.append(len(uniq))
        uniques.append(uniq)

    nan_stats[&#34;num_uniques&#34;] = len_uniques
    nan_stats[&#34;uniques&#34;] = uniques
    nan_stats.reset_index(inplace=True, drop=True)

    return nan_stats


def categorize_df(
    df: pd.DataFrame,
    columns: Optional[List[str]] = None,
    inplace: bool = False,
    drop_original: bool = True,
) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34; Categorize values in columns, and replace value with category.
        If no columns are given, default to all &#39;object&#39; columns
    &#34;&#34;&#34;
    if columns is not None:
        cat_cols = columns
    else:
        cat_cols = df.columns[[dt.name == &#34;object&#34; for dt in df.dtypes.values]]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    df_codes = []
    df_cats = []
    n_cats = []

    for column in cat_cols:
        new_column = f&#34;{column}_cat&#34;
        cat_column = df[column].astype(&#34;category&#34;)
        # By default, NaN is -1. We convert to zero by incrementing all.
        col_codes = cat_column.cat.codes + 1
        resdf[new_column] = col_codes

        # DataFrame with the codes
        df_codes.append(col_codes)
        df_cats.append(cat_column.cat.categories)
        n_cats.append(len(np.unique(col_codes)))

    cat_dict = OrderedDict()
    cat_dict[&#34;column&#34;] = cat_cols
    # MyPy picks up an error in the next line. Bug is where?
    # Additionally, Flake8 will report the MyPy ignore as an error
    cat_dict[&#34;n_categories&#34;] = n_cats  # type: ignore[assignment] # noqa: F821,F821
    cat_dict[&#34;categories&#34;] = df_cats
    cat_dict[&#34;codes&#34;] = df_codes
    cat_df = pd.DataFrame(cat_dict)

    if drop_original:
        resdf.drop(columns=cat_cols, inplace=True)

    return (resdf, cat_df)


def replace_numeric_nulls(
    df: pd.DataFrame,
    columns: Optional[List[str]] = None,
    function: Callable = np.median,
    inplace: bool = False,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Replace nulls in all numerical column with the median (default) or
        another callable function that works on NumPy arrays
    &#34;&#34;&#34;
    if columns is None:
        columns = [
            colname for colname, column in df.items() if is_numeric_dtype(column)
        ]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    fillers = OrderedDict()

    for column in columns:
        values = resdf[resdf[column].notnull()][column].values
        fillers[column] = function(values)

    resdf.fillna(value=fillers, inplace=True)
    return resdf


def object_nan_to_empty(df: pd.DataFrame, inplace: bool = False) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Replace NaN in Pandas object columns with an empty string
        indicating a missing value.
    &#34;&#34;&#34;
    columns = [colname for colname, column in df.items() if is_object_dtype(column)]
    fillers = {c: &#34;&#34; for c in columns}

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    resdf.fillna(value=fillers, inplace=True)
    return resdf


def categorical_columns(
    df: pd.DataFrame, columns: Optional[List[str]] = None, inplace: bool = False
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; For any object columns, create categorical columns instead.
    &#34;&#34;&#34;
    if columns is None:
        columns = [colname for colname, column in df.items() if is_object_dtype(column)]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    for column in columns:
        resdf[column] = df[column].astype(&#34;category&#34;)

    return resdf


def apply_categories(
    df: pd.DataFrame,
    columns: Optional[List[str]] = None,
    inplace: bool = False,
    drop: bool = False,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; For any categorical columns, add a new column with the codes, postfixed with &#39;_cat&#39;.
        If &#39;drop&#39; is tru, drop the original columns
    &#34;&#34;&#34;
    if columns is None:
        columns = [
            colname for colname, column in df.items() if is_categorical_dtype(column)
        ]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    for column in columns:
        catcol = f&#34;{column}_cat&#34;
        resdf[catcol] = resdf[column].cat.codes

    if drop:
        resdf.drop(columns=columns, inplace=True)

    return resdf


def split_dataset(
    df: pd.DataFrame,
    column: str,
    indices: Optional[List[bool]] = None,
    fromto: Optional[Tuple[int, int]] = None,
) -&gt; Tuple[pd.DataFrame, np.array]:
    &#34;&#34;&#34; Split DataFrame into dependent and independent variables. &#39;column&#39; is split
        to a NymPy array. &#39;indices&#39; overrides &#39;fromto&#39;. Indices could be used to
        randomly sample the dataframe. If neither &#39;indices&#39; or &#39;fromto&#39; are given,
        return the whole dataset.
    &#34;&#34;&#34;
    if indices is not None:
        resdf = df[indices].copy(deep=True)
    elif fromto is not None:
        (low, up) = fromto
        resdf = df[low:up].copy(deep=True)
    else:
        resdf = df.copy(deep=True)

    # dependent variable
    y_vals = np.array(resdf[column].values)
    # independent variable(s)
    resdf.drop(columns=column, inplace=True)

    return resdf, y_vals</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dataworks.df_utils.dataframe_utils.add_datefields"><code class="name flex">
<span>def <span class="ident">add_datefields</span></span>(<span>df: pandas.core.frame.DataFrame, column: str, drop_original: bool = False, inplace: bool = False, attrs: Union[List[str], NoneType] = None) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>Add attributes of the date to dataFrame df</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_datefields(
    df: pd.DataFrame,
    column: str,
    drop_original: bool = False,
    inplace: bool = False,
    attrs: Optional[List[str]] = None,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Add attributes of the date to dataFrame df
    &#34;&#34;&#34;
    raw_date = df[column]

    # Pandas datetime attributes
    if attrs is None:
        attributes = [
            &#34;dayofweek&#34;,
            &#34;dayofyear&#34;,
            &#34;is_month_end&#34;,
            &#34;is_month_start&#34;,
            &#34;is_quarter_end&#34;,
            &#34;is_quarter_start&#34;,
            &#34;quarter&#34;,
            &#34;week&#34;,
        ]
    else:
        attributes = attrs

    # Return new?
    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    # Could probably be optimized with pd.apply()
    for attr in attributes:
        new_column = f&#34;{column}_{attr}&#34;
        # https://stackoverflow.com/questions/2612610/
        new_vals = [getattr(d, attr) for d in raw_date]
        resdf[new_column] = new_vals

    if drop_original:
        resdf.drop(columns=column, inplace=True)

    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.add_nan_columns"><code class="name flex">
<span>def <span class="ident">add_nan_columns</span></span>(<span>df: pandas.core.frame.DataFrame, inplace: bool = False, column_list: Union[List[str], NoneType] = None) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>For each column containing NaNs, add a boolean
column specifying if the column is NaN. Can be used
if the data is later imputated.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_nan_columns(
    df: pd.DataFrame, inplace: bool = False, column_list: Optional[List[str]] = None
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; For each column containing NaNs, add a boolean
        column specifying if the column is NaN. Can be used
        if the data is later imputated.
    &#34;&#34;&#34;
    if column_list is not None:
        nan_columns = column_list
    else:
        # Get names of columns containing at least one NaN
        temp = df.isnull().sum() != 0
        nan_columns = temp.index[temp.values]

    # Return new?
    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    for column in nan_columns:
        new_column = f&#34;{column}_isnull&#34;
        nans = df[column].isnull()
        resdf[new_column] = nans

    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.apply_categories"><code class="name flex">
<span>def <span class="ident">apply_categories</span></span>(<span>df: pandas.core.frame.DataFrame, columns: Union[List[str], NoneType] = None, inplace: bool = False, drop: bool = False) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>For any categorical columns, add a new column with the codes, postfixed with '_cat'.
If 'drop' is tru, drop the original columns</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_categories(
    df: pd.DataFrame,
    columns: Optional[List[str]] = None,
    inplace: bool = False,
    drop: bool = False,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; For any categorical columns, add a new column with the codes, postfixed with &#39;_cat&#39;.
        If &#39;drop&#39; is tru, drop the original columns
    &#34;&#34;&#34;
    if columns is None:
        columns = [
            colname for colname, column in df.items() if is_categorical_dtype(column)
        ]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    for column in columns:
        catcol = f&#34;{column}_cat&#34;
        resdf[catcol] = resdf[column].cat.codes

    if drop:
        resdf.drop(columns=columns, inplace=True)

    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.categorical_columns"><code class="name flex">
<span>def <span class="ident">categorical_columns</span></span>(<span>df: pandas.core.frame.DataFrame, columns: Union[List[str], NoneType] = None, inplace: bool = False) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>For any object columns, create categorical columns instead.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def categorical_columns(
    df: pd.DataFrame, columns: Optional[List[str]] = None, inplace: bool = False
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; For any object columns, create categorical columns instead.
    &#34;&#34;&#34;
    if columns is None:
        columns = [colname for colname, column in df.items() if is_object_dtype(column)]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    for column in columns:
        resdf[column] = df[column].astype(&#34;category&#34;)

    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.categorize_df"><code class="name flex">
<span>def <span class="ident">categorize_df</span></span>(<span>df: pandas.core.frame.DataFrame, columns: Union[List[str], NoneType] = None, inplace: bool = False, drop_original: bool = True) -> Tuple[pandas.core.frame.DataFrame, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<section class="desc"><p>Categorize values in columns, and replace value with category.
If no columns are given, default to all 'object' columns</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def categorize_df(
    df: pd.DataFrame,
    columns: Optional[List[str]] = None,
    inplace: bool = False,
    drop_original: bool = True,
) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34; Categorize values in columns, and replace value with category.
        If no columns are given, default to all &#39;object&#39; columns
    &#34;&#34;&#34;
    if columns is not None:
        cat_cols = columns
    else:
        cat_cols = df.columns[[dt.name == &#34;object&#34; for dt in df.dtypes.values]]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    df_codes = []
    df_cats = []
    n_cats = []

    for column in cat_cols:
        new_column = f&#34;{column}_cat&#34;
        cat_column = df[column].astype(&#34;category&#34;)
        # By default, NaN is -1. We convert to zero by incrementing all.
        col_codes = cat_column.cat.codes + 1
        resdf[new_column] = col_codes

        # DataFrame with the codes
        df_codes.append(col_codes)
        df_cats.append(cat_column.cat.categories)
        n_cats.append(len(np.unique(col_codes)))

    cat_dict = OrderedDict()
    cat_dict[&#34;column&#34;] = cat_cols
    # MyPy picks up an error in the next line. Bug is where?
    # Additionally, Flake8 will report the MyPy ignore as an error
    cat_dict[&#34;n_categories&#34;] = n_cats  # type: ignore[assignment] # noqa: F821,F821
    cat_dict[&#34;categories&#34;] = df_cats
    cat_dict[&#34;codes&#34;] = df_codes
    cat_df = pd.DataFrame(cat_dict)

    if drop_original:
        resdf.drop(columns=cat_cols, inplace=True)

    return (resdf, cat_df)</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.inspect_df"><code class="name flex">
<span>def <span class="ident">inspect_df</span></span>(<span>df: pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>Show column types and null values in DataFrame df</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inspect_df(df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Show column types and null values in DataFrame df
    &#34;&#34;&#34;

    resdict = OrderedDict()

    # Inspect nulls
    null_series = df.isnull().sum()
    resdict[&#34;column&#34;] = null_series.index
    resdict[&#34;null_fraction&#34;] = np.round(null_series.values / len(df), 3)
    resdict[&#34;nulls&#34;] = null_series.values
    # Inspect types
    types = df.dtypes.values
    type_names = [t.name for t in types]
    resdict[&#34;type&#34;] = type_names
    # Is numeric?
    is_numeric = []
    for col in df.columns:
        is_numeric.append(is_numeric_dtype(df[col]))
    resdict[&#34;is_numeric&#34;] = is_numeric
    # Dataframe
    resdf = pd.DataFrame(resdict)
    resdf.sort_values(&#34;null_fraction&#34;, inplace=True)
    resdf.reset_index(inplace=True, drop=True)

    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.numeric_nans"><code class="name flex">
<span>def <span class="ident">numeric_nans</span></span>(<span>df: pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>Inspect numerical NaN values of a DataFrame df</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def numeric_nans(df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Inspect numerical NaN values of a DataFrame df
    &#34;&#34;&#34;
    stats = inspect_df(df)
    nan_stats = stats.loc[stats[&#34;is_numeric&#34;] &amp; (stats[&#34;nulls&#34;] &gt; 0)].copy(deep=True)

    len_uniques = []
    uniques = []

    for row in nan_stats[&#34;column&#34;].values:
        uniq = np.unique(df[row][df[row].notnull()].values)
        len_uniques.append(len(uniq))
        uniques.append(uniq)

    nan_stats[&#34;num_uniques&#34;] = len_uniques
    nan_stats[&#34;uniques&#34;] = uniques
    nan_stats.reset_index(inplace=True, drop=True)

    return nan_stats</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.object_nan_to_empty"><code class="name flex">
<span>def <span class="ident">object_nan_to_empty</span></span>(<span>df: pandas.core.frame.DataFrame, inplace: bool = False) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>Replace NaN in Pandas object columns with an empty string
indicating a missing value.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def object_nan_to_empty(df: pd.DataFrame, inplace: bool = False) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Replace NaN in Pandas object columns with an empty string
        indicating a missing value.
    &#34;&#34;&#34;
    columns = [colname for colname, column in df.items() if is_object_dtype(column)]
    fillers = {c: &#34;&#34; for c in columns}

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    resdf.fillna(value=fillers, inplace=True)
    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.replace_numeric_nulls"><code class="name flex">
<span>def <span class="ident">replace_numeric_nulls</span></span>(<span>df: pandas.core.frame.DataFrame, columns: Union[List[str], NoneType] = None, function: Callable = &lt;function median&gt;, inplace: bool = False) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>Replace nulls in all numerical column with the median (default) or
another callable function that works on NumPy arrays</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace_numeric_nulls(
    df: pd.DataFrame,
    columns: Optional[List[str]] = None,
    function: Callable = np.median,
    inplace: bool = False,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Replace nulls in all numerical column with the median (default) or
        another callable function that works on NumPy arrays
    &#34;&#34;&#34;
    if columns is None:
        columns = [
            colname for colname, column in df.items() if is_numeric_dtype(column)
        ]

    if inplace:
        resdf = df
    else:
        resdf = df.copy(deep=True)

    fillers = OrderedDict()

    for column in columns:
        values = resdf[resdf[column].notnull()][column].values
        fillers[column] = function(values)

    resdf.fillna(value=fillers, inplace=True)
    return resdf</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.split_dataset"><code class="name flex">
<span>def <span class="ident">split_dataset</span></span>(<span>df: pandas.core.frame.DataFrame, column: str, indices: Union[List[bool], NoneType] = None, fromto: Union[Tuple[int, int], NoneType] = None) -> Tuple[pandas.core.frame.DataFrame, <built-in function array>]</span>
</code></dt>
<dd>
<section class="desc"><p>Split DataFrame into dependent and independent variables. 'column' is split
to a NymPy array. 'indices' overrides 'fromto'. Indices could be used to
randomly sample the dataframe. If neither 'indices' or 'fromto' are given,
return the whole dataset.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_dataset(
    df: pd.DataFrame,
    column: str,
    indices: Optional[List[bool]] = None,
    fromto: Optional[Tuple[int, int]] = None,
) -&gt; Tuple[pd.DataFrame, np.array]:
    &#34;&#34;&#34; Split DataFrame into dependent and independent variables. &#39;column&#39; is split
        to a NymPy array. &#39;indices&#39; overrides &#39;fromto&#39;. Indices could be used to
        randomly sample the dataframe. If neither &#39;indices&#39; or &#39;fromto&#39; are given,
        return the whole dataset.
    &#34;&#34;&#34;
    if indices is not None:
        resdf = df[indices].copy(deep=True)
    elif fromto is not None:
        (low, up) = fromto
        resdf = df[low:up].copy(deep=True)
    else:
        resdf = df.copy(deep=True)

    # dependent variable
    y_vals = np.array(resdf[column].values)
    # independent variable(s)
    resdf.drop(columns=column, inplace=True)

    return resdf, y_vals</code></pre>
</details>
</dd>
<dt id="dataworks.df_utils.dataframe_utils.summarize_df"><code class="name flex">
<span>def <span class="ident">summarize_df</span></span>(<span>df: pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<section class="desc"><p>Show stats;
- rows:
- column types
- columns
- number of columns
- number of cols containing NaN's</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summarize_df(df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Show stats;
        - rows:
            - column types
        - columns
            - number of columns
            - number of cols containing NaN&#39;s
    &#34;&#34;&#34;
    # Original DataFrame
    (nrows, _) = df.shape
    # Stats of DataFrame
    stats = inspect_df(df)
    data_types = np.unique(stats[&#34;type&#34;].values)

    resdict = OrderedDict()

    # Column: data types
    resdict[&#34;type&#34;] = data_types

    ncols_type = []
    ncols_nan = []
    n_nans = []
    n_total = []

    for dt in data_types:
        # Column: number of columns with type
        nc = len(stats[stats[&#34;type&#34;] == dt])
        ncols_type.append(nc)

        # Column: number of columns with NaNs
        nan_cols = stats[(stats[&#34;type&#34;] == dt) &amp; (stats[&#34;nulls&#34;] &gt; 0)]
        ncols_nan.append(len(nan_cols))

        # Column: number of NaNs
        n_nans.append(nan_cols[&#34;nulls&#34;].sum())

        # Column: total number of values
        n_total.append(nc * nrows)

    # Prepare dict for the df
    resdict[&#34;ncols&#34;] = ncols_type
    resdict[&#34;ncols_w_nans&#34;] = ncols_nan
    resdict[&#34;n_nans&#34;] = n_nans
    resdict[&#34;n_total&#34;] = n_total

    # Proportions of NaNs in each column group.
    # Division by zero shouldn&#39;t occur
    nan_frac = np.array(n_nans) / np.array(n_total)
    resdict[&#34;nan_frac&#34;] = np.round(nan_frac, 2)

    resdf = pd.DataFrame(resdict)
    resdf.sort_values(&#34;type&#34;, inplace=True)
    resdf.reset_index(inplace=True, drop=True)

    return resdf</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dataworks.df_utils" href="index.html">dataworks.df_utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dataworks.df_utils.dataframe_utils.add_datefields" href="#dataworks.df_utils.dataframe_utils.add_datefields">add_datefields</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.add_nan_columns" href="#dataworks.df_utils.dataframe_utils.add_nan_columns">add_nan_columns</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.apply_categories" href="#dataworks.df_utils.dataframe_utils.apply_categories">apply_categories</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.categorical_columns" href="#dataworks.df_utils.dataframe_utils.categorical_columns">categorical_columns</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.categorize_df" href="#dataworks.df_utils.dataframe_utils.categorize_df">categorize_df</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.inspect_df" href="#dataworks.df_utils.dataframe_utils.inspect_df">inspect_df</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.numeric_nans" href="#dataworks.df_utils.dataframe_utils.numeric_nans">numeric_nans</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.object_nan_to_empty" href="#dataworks.df_utils.dataframe_utils.object_nan_to_empty">object_nan_to_empty</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.replace_numeric_nulls" href="#dataworks.df_utils.dataframe_utils.replace_numeric_nulls">replace_numeric_nulls</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.split_dataset" href="#dataworks.df_utils.dataframe_utils.split_dataset">split_dataset</a></code></li>
<li><code><a title="dataworks.df_utils.dataframe_utils.summarize_df" href="#dataworks.df_utils.dataframe_utils.summarize_df">summarize_df</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>